{
  "hash": "668e48114d5438a831cb6f2db29a6630",
  "result": {
    "markdown": "---\ntitle: Wonderful World of Probability\n---\n\nIn our day to day life we have to make random decisions. For that we decide if one even is likely to occur. This likelihood is called probability. Now if I say how much is the probability of getting **Head** or **Tail** in a coin toss the math will tell us it has a 50/50 chance. But that rarely happens when you do a coin toss mulitple times. The magic is when you do it for a large number or times, the chances goes closer and closer to the mathematical probability. That is the magic happening in real time with large number of events.\n\n## Introducing Bayes' Theorem\n\nBayes' Theorem helps us understand how the probability of an event changes as we gain more information.\n\n**Mathematical Representation**\nBayes' Theorem is mathematically expressed as:\n\n$$\nP(A | B) = \\frac{P(B | A) \\times P(A)}{P(B)}\n$$\n\nWhere:\n\n- $P(A | B)$ is the probability of event A occurring given that B is true.\n- $P(B | A)$ is the probability of event B occurring given that A is true.\n- $P(A)$ is the probability of event A.\n- $P(B)$ is the probability of event B.\n\n## Bayes' Theorem in Action!\n\n# Bayes' Theorem Application on Penguin Dataset\n\nWe have a dataset containing different species of penguins, and we're interested in two species: Adelie and Chinstrap. Our goal is to answer:\n\n\"What is the probability that a penguin is of the Chinstrap species given that it has a certain flipper length?\"\n\nTo use Bayes' Theorem, we need the following probabilities:\n\n- **The prior probability $P(\\text{Chinstrap})$**: The overall probability of a penguin being a Chinstrap species in the dataset.\n- **The likelihood $P(\\text{Flipper Length} \\mid \\text{Chinstrap})$**: The probability of observing the specific flipper length given that the penguin is a Chinstrap.\n- **The marginal probability $P(\\text{Flipper Length})$**: The overall probability of observing this specific flipper length among all penguins in the dataset.\n\nBayes' Theorem is applied as follows:\n\n$$ P(\\text{Chinstrap} \\mid \\text{Flipper Length}) = \\frac{P(\\text{Flipper Length} \\mid \\text{Chinstrap}) \\times P(\\text{Chinstrap})}{P(\\text{Flipper Length})} $$\n\n::: {.cell tags='[]' execution_count=1}\n``` {.python .cell-code}\nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\n\n# Load the penguins dataset\ndf = sns.load_dataset(\"penguins\")\n\n# Let's assume we are interested in a flipper length of 200 mm\nflipper_length = 200\n\np_chinstrap = len(df[df['species'] == 'Chinstrap']) / len(df)\n\nchinstrap_data = df[df['species'] == 'Chinstrap']['flipper_length_mm'].dropna()\nlikelihood = stats.norm(chinstrap_data.mean(), chinstrap_data.std()).pdf(flipper_length)\n\n\nall_flipper_data = df['flipper_length_mm'].dropna()\nmarginal = stats.norm(all_flipper_data.mean(), all_flipper_data.std()).pdf(flipper_length)\n\n# Apply Bayes' Theorem\nbayes_result = (likelihood * p_chinstrap) / marginal\nbayes_result\n```\n\n::: {.cell-output .cell-output-display execution_count=1}\n```\n0.3290309502085686\n```\n:::\n:::\n\n\n## Probability Density Function (PDF)\n\nA PDF is a function that describes the relative likelihood for a continuous random variable to take on a given value. In simpler terms, it shows how the values of a continuous variable are distributed. \n\nIn a PDF, the y-axis represents the density, not the probability. For continuous random variables, the probability of observing any single exact value is essentially zero because there are infinitely many possible values. Instead, the area under the curve of the PDF within a range of values indicates the probability of the variable falling within that range.The total area under the PDF curve equals 1, representing the total probability space.\n\n::: {.cell tags='[]' execution_count=2}\n``` {.python .cell-code}\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(6, 3.5))\n\n# Plot for all penguins\nsns.histplot(all_flipper_data, kde=True, stat=\"density\", label='All Penguins')\n# Plot for Chinstrap penguins\nsns.histplot(chinstrap_data, kde=True, stat=\"density\", color='salmon', label='Chinstrap Penguins')\n\nplt.axvline(x=flipper_length, color='red', linestyle='--')\nplt.text(flipper_length+1, 0.02, f'Flipper Length {flipper_length}mm', rotation=90, color='red')\n\nplt.title('Probability Density Function of Flipper Lengths')\nplt.xlabel('Flipper Length (mm)')\nplt.ylabel('Density')\nplt.legend()\n\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-3-output-1.png){width=523 height=339}\n:::\n:::\n\n\nWhen dealing with continuous data (like flipper length in penguins), the concepts of prior, likelihood, and posterior in Bayes' Theorem are represented as continuous probability distributions, and these are often expressed as PDFs.\n\nIn our penguin dataset, we used Bayes' Theorem to update the probability of a penguin being of the Chinstrap species given its flipper length. The prior probability (belief about the proportion of Chinstrap penguins before seeing the flipper length), likelihood (probability of observing a certain flipper length given that the penguin is a Chinstrap), and the marginal probability (overall probability of observing this flipper length) are all part of this Bayesian update mechanism.\n\n\nThe PDFs represent these probabilities for the continuous variable of flipper length. By calculating the area under these curves (or using a probability density function to get a specific density value), we are  able to apply Bayes' Theorem in a context where the variables are continuous.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}