{
  "hash": "e0afc036c258ed5d5304d9c55b5bc273",
  "result": {
    "markdown": "---\ntitle: All About Anomaly in Data\n---\n\nIn this age where data is king, we are awash in a sea of big data, larger and more complex than ever before. Within this vast expanse of information lies a subtle yet critical challenge: the presence of anomalies. Think of anomalies as the rebels of the data world, defying the norms and expectations of typical behavior. These aren't just quirky data points; they're potential game-changers. They can skew our insights, open doors to cyber threats, and lead our carefully calibrated models astray. Identifying and understanding these anomalies isn't just a technical puzzle; it's a crucial quest to safeguard the integrity and efficacy of our data-driven universe. The ability to pinpoint and interpret these unusual patterns is more than a skill—it's an essential armor in the arsenal of any data warrior navigating this ever-expanding digital landscape..\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(0)\nx = np.linspace(0, 10, 100)\ny = np.sin(x) + np.random.normal(0, 0.1, 100)\n\n# Introducing outliers/anomalies\ny[np.random.randint(0, len(y), 5)] += np.random.normal(3, 1, 5)\n\n# Identifying the anomalies\nthreshold = y.mean() + 1 * y.std()\nanomalies = y > threshold\n\ndata = np.column_stack((x, y))\ndf = pd.DataFrame(data, columns=['X', 'Y'])\ndf['Anomaly'] = anomalies\n\n# Plotting \nplt.figure(figsize=(8, 5))\nsns.scatterplot(x='X', y='Y', hue='Anomaly', data=df, palette={False: 'blue', True: 'red'})\n\nplt.axhline(y=threshold, color='green', linestyle='--', label='Threshold')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.grid()\nplt.title('Data Points with Anomalies Highlighted (Seaborn)')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-2-output-1.png){width=662 height=449}\n:::\n:::\n\n\nThe plot showcases how a general anomaly can look like in a data distribution, these anomalies are separated by a threshold. If you look at the plot, it can be very evident that the outliers does not follow the actual pattern. \n\n## Machine Learning in Anomaly Detection\n\nMachine learning excels in identifying patterns within datasets, a capability that proves especially useful in anomaly detection. By mastering the art of pattern recognition, machine learning models are not only able to discern regularities in data but also adeptly pinpoint anomalies—those instances that deviate from established norms. Today, I'll introduce you to a particularly effective model designed for this purpose. This model simplifies the complex task of detecting outliers, leveraging advanced algorithms to efficiently identify deviations in any dataset, thus offering a robust solution for a variety of anomaly detection challenges.\n\n## DBSCAN\n\nDBSCAN is a density based clustering algorithm which is really good for finding arbitary shaped clusters. Imagine you're a detective looking at a bustling crowd, trying to identify groups of friends based on how closely they stand together. This is similar to how DBSCAN works with data points.\n\nWe will apply this algorithm to find out anomaly in the IRIS dataset. It has many repositories but the one from UCI Machine Learning Repository has two wrong data points.\n\nsource: https://archive.ics.uci.edu/static/public/53/iris.zip\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\ndf = pd.read_csv(\"https://raw.githubusercontent.com/uiuc-cse/data-fa14/gh-pages/data/iris.csv\")\nprint(df.head(-4))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n     sepal_length  sepal_width  petal_length  petal_width    species\n0             5.1          3.5           1.4          0.2     setosa\n1             4.9          3.0           1.4          0.2     setosa\n2             4.7          3.2           1.3          0.2     setosa\n3             4.6          3.1           1.5          0.2     setosa\n4             5.0          3.6           1.4          0.2     setosa\n..            ...          ...           ...          ...        ...\n141           6.9          3.1           5.1          2.3  virginica\n142           5.8          2.7           5.1          1.9  virginica\n143           6.8          3.2           5.9          2.3  virginica\n144           6.7          3.3           5.7          2.5  virginica\n145           6.7          3.0           5.2          2.3  virginica\n\n[146 rows x 5 columns]\n```\n:::\n:::\n\n\nLets perform a simple model fitting with **petal length** and **petal width**\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nfrom sklearn.cluster import DBSCAN\nmodel=DBSCAN()\nmodel.fit(df[[\"sepal_length\", \"sepal_width\"]])\\\n\nmodel.get_params(deep=True)\n```\n\n::: {.cell-output .cell-output-display execution_count=3}\n```\n{'algorithm': 'auto',\n 'eps': 0.5,\n 'leaf_size': 30,\n 'metric': 'euclidean',\n 'metric_params': None,\n 'min_samples': 5,\n 'n_jobs': None,\n 'p': None}\n```\n:::\n:::\n\n\nWe need to look at one parameter called epsilon (ε). Epsilon is like the detective's line of sight, determining how far he can see around each point. Here we have ε = 0.5\n\nFirst, maybe we can see if the model can really detect the two wrong data points. We can call them outliers or data anomaly. \n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nlabels = model.labels_\nprint(pd.Series(labels).value_counts())\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n 0    148\n-1      2\ndtype: int64\n```\n:::\n:::\n\n\nAs we can see, the model really could find out two wrong data points. You will see the DBSCAN model labelled them as -1. Just to be sure, we can plot the labels. In the image you can see our two outliers colored orange dots.\n\n::: {.cell execution_count=5}\n``` {.python .cell-code}\ndf['Outlier'] = labels == -1\n\nplt.figure(figsize=(6, 5))\nsns.scatterplot(data=df, x=\"sepal_length\", y=\"sepal_width\", hue=\"Outlier\",s = 50, palette=\"deep\",legend=False)\nplt.title(\"DBSCAN Outlier Detection\")\nplt.xlabel(\"Sepal Length\")\nplt.ylabel(\"Sepal Width\")\nplt.grid()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-6-output-1.png){width=516 height=449}\n:::\n:::\n\n\nNow, the performance of the model can vary with different epsilon values. That is why, when trying to detect anomalies in your data, always look at the graphical representation of data clusters and anomalies to judge the model performance. Following is a plot showing the model output on three different epsilon values. We can compare the results because we know there are two outliers. As we can see, using ε = 0.1 and 0.7 gave us not ideal results. So, use your judgement always. Good Luck!\n\n::: {.cell execution_count=6}\n``` {.python .cell-code}\ndef plot_dbscan(df, eps_values):\n    plt.figure(figsize=(10,3))\n\n    for i, eps in enumerate(eps_values, 1):\n        model = DBSCAN(eps=eps)\n        df['labels'] = model.fit_predict(df[[\"sepal_length\", \"sepal_width\"]])\n\n        plt.subplot(1, len(eps_values), i)\n        sns.scatterplot(data=df, x=\"sepal_length\", y=\"sepal_width\", hue=\"labels\", palette=\"deep\", legend=False)\n        plt.title(f\"DBSCAN with eps={eps}\")\n        plt.xlabel(\"Sepal Length\")\n        plt.ylabel(\"Sepal Width\")\n\n    plt.tight_layout()\n    plt.show()\n\n\neps_values = [0.1, 0.5, 0.7]\n\n\nplot_dbscan(df, eps_values)\n```\n\n::: {.cell-output .cell-output-display}\n![](index_files/figure-html/cell-7-output-1.png){width=950 height=278}\n:::\n:::\n\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}